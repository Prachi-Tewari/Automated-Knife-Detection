{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load pre-trained model\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Function to load image\n",
    "def load_image(img_path):\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img_tensor = transform(img).unsqueeze(0)\n",
    "        return img, img_tensor\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {img_path}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cam(model, img_tensor):\n",
    "    # Get the last convolutional layer\n",
    "    final_conv_layer = model.layer4[-1].conv2\n",
    "    feature_map = None\n",
    "    def hook_function(module, input, output):\n",
    "        nonlocal feature_map\n",
    "        feature_map = output\n",
    "    hook = final_conv_layer.register_forward_hook(hook_function)\n",
    "    \n",
    "    # Forward pass through the model\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "    hook.remove()\n",
    "    \n",
    "    # Get the weights of the final fully connected layer\n",
    "    params = list(model.parameters())\n",
    "    weight_softmax = params[-2]\n",
    "    \n",
    "    # Get the class with the highest score\n",
    "    _, class_idx = torch.max(output, 1)\n",
    "    \n",
    "    # Get the CAM\n",
    "    cam = torch.zeros(feature_map.shape[2:])\n",
    "    for i, w in enumerate(weight_softmax[class_idx]):\n",
    "        cam += w * feature_map[0, i, :, :]\n",
    "    cam = cam.cpu().numpy()\n",
    "    cam = cam - cam.min()\n",
    "    cam = cam / cam.max()\n",
    "    return cam\n",
    "\n",
    "def visualize_cam(img, cam):\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(cam, cmap='jet', alpha=0.5)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2048) must match the size of tensor b (7) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_name \u001b[38;5;129;01min\u001b[39;00m positive_images[:\u001b[38;5;241m5\u001b[39m]:  \u001b[38;5;66;03m# Just to visualize a few examples\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(positive_folder, img_name)\n\u001b[1;32m---> 18\u001b[0m     \u001b[43mdetect_knives\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Run inference on negative images\u001b[39;00m\n\u001b[0;32m     21\u001b[0m negative_images \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(negative_folder)\n",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m, in \u001b[0;36mdetect_knives\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m cam \u001b[38;5;241m=\u001b[39m \u001b[43mget_cam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m visualize_cam(img, cam)\n",
      "Cell \u001b[1;32mIn[6], line 25\u001b[0m, in \u001b[0;36mget_cam\u001b[1;34m(model, img_tensor)\u001b[0m\n\u001b[0;32m     23\u001b[0m cam \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(feature_map\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:])\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(weight_softmax[class_idx]):\n\u001b[1;32m---> 25\u001b[0m     cam \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfeature_map\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     26\u001b[0m cam \u001b[38;5;241m=\u001b[39m cam\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     27\u001b[0m cam \u001b[38;5;241m=\u001b[39m cam \u001b[38;5;241m-\u001b[39m cam\u001b[38;5;241m.\u001b[39mmin()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (2048) must match the size of tensor b (7) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Define the paths to your dataset\n",
    "positive_folder = r'D:\\Weapon Detection Project DRDO\\KnivesImagesDatabase\\POSITIVES_ALL'\n",
    "negative_folder = r'D:\\Weapon Detection Project DRDO\\KnivesImagesDatabase\\NEGATIVES_ALL'\n",
    "\n",
    "# Function to detect knives\n",
    "def detect_knives(image_path):\n",
    "    img, img_tensor = load_image(image_path)\n",
    "    if img_tensor is None:\n",
    "        print(f\"Skipping {image_path}\")\n",
    "        return\n",
    "    cam = get_cam(model, img_tensor)\n",
    "    visualize_cam(img, cam)\n",
    "\n",
    "# Run inference on positive images\n",
    "positive_images = os.listdir(positive_folder)\n",
    "for img_name in positive_images[:5]:  # Just to visualize a few examples\n",
    "    img_path = os.path.join(positive_folder, img_name)\n",
    "    detect_knives(img_path)\n",
    "\n",
    "# Run inference on negative images\n",
    "negative_images = os.listdir(negative_folder)\n",
    "for img_name in negative_images[:5]:  # Just to visualize a few examples\n",
    "    img_path = os.path.join(negative_folder, img_name)\n",
    "    detect_knives(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
